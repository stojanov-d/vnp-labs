{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rODb9vHvIEbp"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U4KmHBd2cdx9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 16:59:50.889909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737043190.924463   26310 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737043190.935023   26310 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-16 16:59:50.970192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Add as many imports as you need.\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,precision_recall_fscore_support,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNMMoUiUIW3L"
   },
   "source": [
    "# Laboratory Exercise - Run Mode (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rAh_91OIjeS"
   },
   "source": [
    "## Introduction\n",
    "This laboratory assignment's primary objective is to fine-tune a pre-trained language model for binary classification on a dataset consisting of Spotify user reviews. The dataset contains two attributes:\n",
    "\n",
    "+ **review** - A text column containing user feedback, opinions, and experiences with the Spotify application.\n",
    "+ **sentiment** - A categorical column indicating whether the review has a positive or negative sentiment.\n",
    "\n",
    "Your task involves training a model to predict the **sentiment** (either \"positive\" or \"negative\") based on the content of the **review**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBYI-EypaWom"
   },
   "source": [
    "## The Spotify User Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCm1qm1mZwMr"
   },
   "source": [
    "Load the dataset using the `datasets` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KMOn4fgcZn8s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "ds = load_dataset('csv', data_files={'train':'../datasets/spotify-user-reviews.csv'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_labels(data):\n",
    "    if data['label'] == 'positive':\n",
    "        data['label'] = 1\n",
    "    else:\n",
    "        data['label'] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(change_labels)\n",
    "ds['train']['label'][:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tls69_PrbJKW"
   },
   "source": [
    "## Dataset Splitting\n",
    "Partition the dataset into training and testing sets with an 80:20 ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PjGGGMxebeoB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "split_ds = ds['train'].train_test_split(test_size=0.2,seed=42)\n",
    "split_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLnr8v_dWO1i"
   },
   "source": [
    "## Tokenization\n",
    "Tokenize the texts using the `AutoTokenizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "esakOh8iWYEN"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(example):\n",
    "    tokenized = tokenizer(example['review'],padding=True,truncation=True,max_length=32)\n",
    "    tokenized['labels'] = example['label']\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = split_ds.map(tokenize_func,batched=True)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIkAR1Hibiwr"
   },
   "source": [
    "## Fine-tuning a Pre-trained Language Model for Classification\n",
    "Fine-tune a pre-trained language model for classification on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWn1pafKbnxH"
   },
   "source": [
    "Define the model using the `AutoModelForSequenceClassification` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IXFIrQthbnkb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuQCSxZbYJOq"
   },
   "source": [
    "Define the traning parameters using the `TrainingArguments` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p3sVs-L1YJHu"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "args = TrainingArguments(\n",
    "    output_dir='./trainer',\n",
    "    per_device_eval_batch_size=16,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    metric_for_best_model='accuracy'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVvRS4L1YKHp"
   },
   "source": [
    "Define the training using the `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels,predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\":accuracy,\n",
    "        \"precision\":precision,\n",
    "        \"recall\":recall,\n",
    "        \"f1\":f1\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O7cyG3PhYJ_M"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFZr21HxYkko"
   },
   "source": [
    "Fine-tune (train) the pre-trained lanugage model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U9Dz0P11Ykeh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284275</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.889001</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.889000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.36181317138671876, metrics={'train_runtime': 140.3855, 'train_samples_per_second': 56.986, 'train_steps_per_second': 0.89, 'total_flos': 66233699328000.0, 'train_loss': 0.36181317138671876, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyXZwAVab8Cp"
   },
   "source": [
    "Use the trained model to make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EvMfVum6b_9b"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)  # Convert logits to class predictions\n",
    "y_true = np.array(tokenized_ds['test']['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VxAvDPtcNCh"
   },
   "source": [
    "Assess the performance of the model by using different metrics provided by the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "V4axpktycQhp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      1001\n",
      "           1       0.89      0.89      0.89       999\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwnD_qSpIeXG"
   },
   "source": [
    "# Laboratory Exercise - Bonus Task (+ 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5xnEDq3A2h"
   },
   "source": [
    "Implement a machine learning pipeline to classify Spotify user reviews as positive or negative. Use TF-IDF vectorization to transform the review text into numerical features, and train a logistic regression model on the transformed data. Split the dataset into training and testing sets, fit the pipeline on the training data, and evaluate its performance using metrics such as precision, recall, and F1-score. To gain insights into the most influential words or phrases associated with positive and negative reviews, analyze the coefficients from the logistic regression model trained on the TF-IDF features. Present the top keywords for each sentiment in a table or a bar chart to provide a clear understanding of the terms driving user feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akxvW5SZ3DoV"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
