{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rODb9vHvIEbp"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4KmHBd2cdx9"
   },
   "outputs": [],
   "source": [
    "# Add as many imports as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNMMoUiUIW3L"
   },
   "source": [
    "# Laboratory Exercise - Run Mode (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rAh_91OIjeS"
   },
   "source": [
    "## Introduction\n",
    "In this laboratory assignment, the primary objective is to use Long Short-Term Memory (LSTM) networks for time series forecasting in order to predict the current **close price** of the Dow Jones Industrial Average index. To accomplish this use data from the past 7 days, which includes numeric information and news information. The goal is to employ LSTM, a type of recurrent neural network, to effectively forecast one future step for the index price (the following day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBYI-EypaWom"
   },
   "source": [
    "## The DIJA Dataset\n",
    "\n",
    "This dataset consists of daily price records for the value of the Dow Jones Industrial Average index. The dataset includes the following attributes:\n",
    "\n",
    "- Date - date in the format YYYY-MM-DD,\n",
    "- Open - open price of the index on the specified date\n",
    "- Close - close price of the index on the specified date\n",
    "- High - high price of the index on the specified date\n",
    "- Low - low price of the index on the specified date\n",
    "- Volume - number of trades\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reddit News Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of news headlines for a certain date that might impact the price:\n",
    "\n",
    "- Date - date in the format YYYY-MM-DD,\n",
    "- News - news headline scraped from Reddit\n",
    "\n",
    "<b>Note: You might have multiple headlines for each date. The number of news per date might not be the same for each date. <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCm1qm1mZwMr"
   },
   "source": [
    "Load the datasets into a `pandas` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMOn4fgcZn8s"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5slwyyhCKRo9"
   },
   "source": [
    "Merge the datasets (be careful you can get multiple rows per date which is not desirable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFY6TKhGKOY4"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZceBEFuiGpI"
   },
   "source": [
    "## Feauture Extraction\n",
    "\n",
    "\n",
    "1. DIJA Table\n",
    "Apply a lag of one, up to 7 days to each feature, creating a set of features representing the index price from the previous 7 days. To maintain dataset integrity, eliminate any resulting missing values at the beginning of the dataset.\n",
    "\n",
    "2. Reddit News Table\n",
    "Create a numeric representation for the news (for example average embedding or average sentiment). <b> You must create lags of the news features as well since we will not know the news for the future. </b>\n",
    "\n",
    "Hint: Use `df['column_name'].shift(period)`. Check the documentation at https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-xymWvjTFt-"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tls69_PrbJKW"
   },
   "source": [
    "## Dataset Splitting\n",
    "Partition the dataset into training and testing sets with an 80:20 ratio.\n",
    "\n",
    "**WARNING: DO NOT SHUFFLE THE DATASET.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjGGGMxebeoB"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwhDHS-nRRhW"
   },
   "source": [
    "## Feauture Scaling\n",
    "Scale the extracted features using an appropriate scaler if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlvbs68wRaVj"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI53ZRmfW8WG"
   },
   "source": [
    "## Feature Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK9naW8AXVaU"
   },
   "source": [
    "Reshape the feature dimensions into the shape `(samples, timesteps, features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3D-1-V9bW8tl"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIkAR1Hibiwr"
   },
   "source": [
    "## Long Short-Term Memory (LSTM) Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWn1pafKbnxH"
   },
   "source": [
    "Define the forecasting model using the **Keras Sequential API** (`keras.models.Sequential`), incorporating one or more LSTM layers along with additional relevant layers (`keras.layers`). Be cautious when specifying the configuration of the final layer to ensure proper model output for the forecasting task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXFIrQthbnkb"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAM-g59xSO4V"
   },
   "source": [
    "Compile the previously defined model specifying **loss function** (`keras.losses`), **optimizer** (`keras.optimizers`) and **evaluation metrics** (`keras.metics`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBtCCy9VSQpF"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lygUzi0QTXgZ"
   },
   "source": [
    "Train the model on the training set, specifying the **batch size** and **number of epochs** for the training process. Allocate 20% of the samples for **validation**, and ensure that the dataset remains **unshuffled** during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fkj3k5p8TXEF"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgK9j0GrUs2l"
   },
   "source": [
    "Create a line plot illustrating both the **training** and **validation loss** over the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2u1RylwfUtR0"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyXZwAVab8Cp"
   },
   "source": [
    "Use the trained model to make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvMfVum6b_9b"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VxAvDPtcNCh"
   },
   "source": [
    "Assess the performance of the model by using different metrics provided by the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4axpktycQhp"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X01Q7Pb9VOAI"
   },
   "source": [
    "Create a line plot in order to compare the actual and predicted mean temperatures for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeS852CkVPVJ"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
